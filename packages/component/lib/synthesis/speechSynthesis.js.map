{"version":3,"sources":["../../src/synthesis/speechSynthesis.js"],"names":["DEFAULT_REGION","DEFAULT_OUTPUT_FORMAT","SpeechSynthesis","onvoiceschanged","region","outputFormat","queue","AudioContextQueue","_isAboutToSpeak","stop","utterance","SpeechSynthesisUtterance","Error","fetchToken","accessToken","Promise","resolve","reject","addEventListener","preload","push"],"mappings":";;;;;;;;;;;;;;;;;AAAA;;AACA;;AACA;;AAEA,IAAMA,cAAc,GAAG,QAAvB,C,CACA;;AACA,IAAMC,qBAAqB,GAAG,kCAA9B;;IAEMC,e;;;AACJ,6BAAc;AAAA;AACZ,SAAKC,eAAL,GAAuB,IAAvB;AACA,SAAKC,MAAL,GAAcJ,cAAd;AACA,SAAKK,YAAL,GAAoBJ,qBAApB;AACA,SAAKK,KAAL,GAAa,IAAIC,0BAAJ,EAAb;AACA,SAAKC,eAAL,GAAuB,KAAvB;AACD;;;;6BAEQ;AACP,WAAKA,eAAL,GAAuB,KAAvB;AAEA,WAAKF,KAAL,CAAWG,IAAX;AACD;;;gCAEW;AACV,aAAO,2BAAP;AACD;;;;;;iDAEWC,S;;;;;;;;oBACJA,SAAS,YAAYC,iC;;;;;sBACnB,IAAIC,KAAJ,CAAU,mBAAV,C;;;oBAGH,KAAKC,U;;;;;sBACF,IAAID,KAAJ,CAAU,yCAAV,C;;;sBACG,OAAO,KAAKC,UAAZ,KAA2B,U;;;;;sBAC9B,IAAID,KAAJ,CAAU,mHAAV,C;;;AAGR,qBAAKJ,eAAL,GAAuB,IAAvB;;uBAE0B,KAAKK,UAAL,E;;;AAApBC,gBAAAA,W;iDAEC,IAAIC,OAAJ,CAAY,UAACC,OAAD,EAAUC,MAAV,EAAqB;AACtC,sBAAI,KAAI,CAACT,eAAT,EAA0B;AACxBE,oBAAAA,SAAS,CAACQ,gBAAV,CAA2B,KAA3B,EAAkCF,OAAlC;AACAN,oBAAAA,SAAS,CAACQ,gBAAV,CAA2B,OAA3B,EAAoCD,MAApC;AACAP,oBAAAA,SAAS,CAACI,WAAV,GAAwBA,WAAxB;AACAJ,oBAAAA,SAAS,CAACN,MAAV,GAAmB,KAAI,CAACA,MAAxB;AACAM,oBAAAA,SAAS,CAACL,YAAV,GAAyB,KAAI,CAACA,YAA9B;AACAK,oBAAAA,SAAS,CAACS,OAAV;AACD;;AAED,sBAAI,KAAI,CAACX,eAAT,EAA0B;AACxB,oBAAA,KAAI,CAACA,eAAL,GAAuB,KAAvB;;AAEA,oBAAA,KAAI,CAACF,KAAL,CAAWc,IAAX,CAAgBV,SAAhB;AACD;AACF,iBAfM,C;;;;;;;;;;;;;;;;;;eAmBI,IAAIR,eAAJ,E","sourcesContent":["import AudioContextQueue from './AudioContextQueue';\nimport fetchVoices from './fetchVoices';\nimport SpeechSynthesisUtterance from './SpeechSynthesisUtterance';\n\nconst DEFAULT_REGION = 'westus';\n// Supported output format can be found at https://docs.microsoft.com/en-us/azure/cognitive-services/Speech/API-Reference-REST/BingVoiceOutput#Subscription\nconst DEFAULT_OUTPUT_FORMAT = 'audio-16khz-128kbitrate-mono-mp3';\n\nclass SpeechSynthesis {\n  constructor() {\n    this.onvoiceschanged = null;\n    this.region = DEFAULT_REGION;\n    this.outputFormat = DEFAULT_OUTPUT_FORMAT;\n    this.queue = new AudioContextQueue();\n    this._isAboutToSpeak = false;\n  }\n\n  cancel() {\n    this._isAboutToSpeak = false;\n\n    this.queue.stop();\n  }\n\n  getVoices() {\n    return fetchVoices();\n  }\n\n  async speak(utterance) {\n    if (!(utterance instanceof SpeechSynthesisUtterance)) {\n      throw new Error('invalid utterance');\n    }\n\n    if (!this.fetchToken) {\n      throw new Error('SpeechSynthesis: fetchToken must be set');\n    } else if (typeof this.fetchToken !== 'function') {\n      throw new Error('SpeechSynthesis: fetchToken must be a function that returns a Promise and it will resolve to a string-based token');\n    }\n\n    this._isAboutToSpeak = true;\n\n    const accessToken = await this.fetchToken();\n\n    return new Promise((resolve, reject) => {\n      if (this._isAboutToSpeak) {\n        utterance.addEventListener('end', resolve);\n        utterance.addEventListener('error', reject);\n        utterance.accessToken = accessToken;\n        utterance.region = this.region;\n        utterance.outputFormat = this.outputFormat;\n        utterance.preload();\n      }\n\n      if (this._isAboutToSpeak) {\n        this._isAboutToSpeak = false;\n\n        this.queue.push(utterance);\n      }\n    });\n  }\n}\n\nexport default new SpeechSynthesis()\n"],"file":"speechSynthesis.js"}