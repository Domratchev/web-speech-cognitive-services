{"version":3,"sources":["../../src/synthesis/speechSynthesis.js"],"names":["DEFAULT_OUTPUT_FORMAT","SpeechSynthesis","onvoiceschanged","outputFormat","queue","AudioContextQueue","stop","utterance","SpeechSynthesisUtterance","Error","fetchToken","accessToken","resolve","reject","addEventListener","preload","push"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;;;;AACA;;;;AACA;;;;;;AAEA;AACA,IAAMA,wBAAwB,kCAA9B;;IAEMC,e;AACJ,6BAAc;AAAA;;AACZ,SAAKC,eAAL,GAAuB,IAAvB;AACA,SAAKC,YAAL,GAAoBH,qBAApB;AACA,SAAKI,KAAL,GAAa,IAAIC,2BAAJ,EAAb;AACD;;;;6BAEQ;AACP,WAAKD,KAAL,CAAWE,IAAX;AACD;;;gCAEW;AACV,aAAO,4BAAP;AACD;;;;2GAEWC,S;;;;;;;;oBACJA,qBAAqBC,kC;;;;;sBACnB,IAAIC,KAAJ,CAAU,mBAAV,C;;;oBAGH,KAAKC,U;;;;;sBACF,IAAID,KAAJ,CAAU,yCAAV,C;;;sBACG,OAAO,KAAKC,UAAZ,KAA2B,U;;;;;sBAC9B,IAAID,KAAJ,CAAU,mHAAV,C;;;;uBAGkB,KAAKC,UAAL,E;;;AAApBC,2B;iDAEC,sBAAY,UAACC,OAAD,EAAUC,MAAV,EAAqB;AACtCN,4BAAUO,gBAAV,CAA2B,KAA3B,EAAkCF,OAAlC;AACAL,4BAAUO,gBAAV,CAA2B,OAA3B,EAAoCD,MAApC;AACAN,4BAAUI,WAAV,GAAwBA,WAAxB;AACAJ,4BAAUJ,YAAV,GAAyB,MAAKA,YAA9B;AACAI,4BAAUQ,OAAV;;AAEA,wBAAKX,KAAL,CAAWY,IAAX,CAAgBT,SAAhB;AACD,iBARM,C;;;;;;;;;;;;;;;;;;;;kBAYI,IAAIN,eAAJ,E","file":"speechSynthesis.js","sourcesContent":["import AudioContextQueue from './AudioContextQueue';\nimport fetchVoices from './fetchVoices';\nimport SpeechSynthesisUtterance from './SpeechSynthesisUtterance';\n\n// Supported output format can be found at https://docs.microsoft.com/en-us/azure/cognitive-services/Speech/API-Reference-REST/BingVoiceOutput#Subscription\nconst DEFAULT_OUTPUT_FORMAT = 'audio-16khz-128kbitrate-mono-mp3';\n\nclass SpeechSynthesis {\n  constructor() {\n    this.onvoiceschanged = null;\n    this.outputFormat = DEFAULT_OUTPUT_FORMAT;\n    this.queue = new AudioContextQueue();\n  }\n\n  cancel() {\n    this.queue.stop();\n  }\n\n  getVoices() {\n    return fetchVoices();\n  }\n\n  async speak(utterance) {\n    if (!(utterance instanceof SpeechSynthesisUtterance)) {\n      throw new Error('invalid utterance');\n    }\n\n    if (!this.fetchToken) {\n      throw new Error('SpeechSynthesis: fetchToken must be set');\n    } else if (typeof this.fetchToken !== 'function') {\n      throw new Error('SpeechSynthesis: fetchToken must be a function that returns a Promise and it will resolve to a string-based token');\n    }\n\n    const accessToken = await this.fetchToken();\n\n    return new Promise((resolve, reject) => {\n      utterance.addEventListener('end', resolve);\n      utterance.addEventListener('error', reject);\n      utterance.accessToken = accessToken;\n      utterance.outputFormat = this.outputFormat;\n      utterance.preload();\n\n      this.queue.push(utterance);\n    });\n  }\n}\n\nexport default new SpeechSynthesis()\n"]}